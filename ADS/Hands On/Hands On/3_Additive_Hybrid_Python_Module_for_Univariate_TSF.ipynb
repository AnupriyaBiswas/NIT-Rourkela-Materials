{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "253892c7-895c-4ade-93e0-4c67341ccb98",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td width=15%><img src=\"https://www.nitrkl.ac.in/assets/images/logo.png\"></img></td>\n",
    "<td><center><h1>National Institute of Technology\n",
    "Rourkela, Odisha, India, 769008</h1><h2>Department of Computer Science Engineering</h2></center></td>\n",
    "</tr>\n",
    "<tr><td colspan=2><center><h3>National Workshop on CFTSFDL-2024</h3></br>\n",
    "            <b>(Day-2 Hands-on)</b></center></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38be523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ae4bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten,LSTM\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.metrics import RootMeanSquaredError,mean_absolute_percentage_error\n",
    "from keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeccf6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate time series into patterns\n",
    "def get_Patterns(TSeries, n_inputs,h):\n",
    "    X,y,z = pd.DataFrame(np.zeros((len(TSeries)-n_inputs-h+1,n_inputs))), pd.DataFrame(), pd.DataFrame()\n",
    "    for i in range(len(TSeries)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_inputs + h - 1\n",
    "        # check if we are beyond the time series\n",
    "        if end_ix > len(TSeries)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        for j in range(n_inputs):\n",
    "            X.loc[i,j]=TSeries.iloc[i+j,0]\n",
    "        i=i+n_inputs\n",
    "        #y=y.append(TSeries.iloc[end_ix], ignore_index = True)\n",
    "        y=pd.concat([y, TSeries.iloc[end_ix]], ignore_index=True)\n",
    "    return pd.DataFrame(X),pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9c68a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# originalData should be a Column Vectored DataFrame\n",
    "def minmaxNorm(originalData, lenTrainValidation):\n",
    "    # Maximum Value\n",
    "    max2norm=max(originalData.iloc[0:lenTrainValidation,0])\n",
    "    # Minimum Value\n",
    "    min2norm=min(originalData.iloc[0:lenTrainValidation,0])\n",
    "    lenOriginal=len(originalData)\n",
    "    normalizedData=np.zeros(lenOriginal)   \n",
    "    normalizedData = []\n",
    "    #Normalize using Min-Max Normalization\n",
    "    for i in range (lenOriginal):\n",
    "        normalizedData.append((originalData.iloc[i]-min2norm)/(max2norm-min2norm))    \n",
    "    return pd.DataFrame(normalizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c481549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# originalData and forecastedData should be Column Vectored DataFrames\n",
    "def minmaxDeNorm( originalData, forecastedData, lenTrainValidation):\n",
    "    # Maximum Value\n",
    "    max2norm=max(originalData.iloc[0:lenTrainValidation,0])\n",
    "    # Minimum Value\n",
    "    min2norm=min(originalData.iloc[0:lenTrainValidation,0])\n",
    "    lenOriginal=len(originalData)\n",
    "    denormalizedData=[]   \n",
    "    #De-Normalize using Min-Max Normalization\n",
    "    for i in range (lenOriginal):\n",
    "        denormalizedData.append((forecastedData.iloc[i]*(max2norm-min2norm))+min2norm)  \n",
    "    return pd.DataFrame(denormalizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5142a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeseries_Data and forecasted_value should be Column Vectored DataFrames\n",
    "def findRMSE( Timeseries_Data, forecasted_value,lenTrainValidation):\n",
    "    l=Timeseries_Data.shape[0]\n",
    "    lenTest=l-lenTrainValidation\n",
    "    trainRMSE=0;\n",
    "    for i in range (lenTrainValidation):\n",
    "        trainRMSE=trainRMSE+np.power((forecasted_value.iloc[i,0]-Timeseries_Data.iloc[i,0]),2) \n",
    "    trainRMSE=np.sqrt(trainRMSE/lenTrainValidation)\n",
    "\n",
    "    testRMSE=0;\n",
    "    for i in range (lenTrainValidation,l,1):\n",
    "        testRMSE=testRMSE+np.power((forecasted_value.iloc[i,0]-Timeseries_Data.iloc[i,0]),2)\n",
    "    testRMSE=np.sqrt(testRMSE/lenTest)\n",
    "    return trainRMSE, testRMSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9147158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeseries_Data and forecasted_value should be Column Vectored DataFrames\n",
    "def findMAE( Timeseries_Data, forecasted_value,lenTrainValidation):\n",
    "    l=Timeseries_Data.shape[0]\n",
    "    lenTest=l-lenTrainValidation\n",
    "    trainMAE=0;\n",
    "    for i in range (lenTrainValidation):\n",
    "        trainMAE=trainMAE+np.abs(forecasted_value.iloc[i,0]-Timeseries_Data.iloc[i,0]) \n",
    "    trainMAE=(trainMAE/(lenTrainValidation));\n",
    "\n",
    "    testMAE=0;\n",
    "    for i in range (lenTrainValidation,l,1):\n",
    "        testMAE=testMAE+np.abs(forecasted_value.iloc[i,0]-Timeseries_Data.iloc[i,0])\n",
    "    testMAE=(testMAE/lenTest);\n",
    "    return trainMAE, testMAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fde0e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_Fitness_LSTM(x,y,lenValid,lenTest):\n",
    "    NOP=len(y)\n",
    "    n_features=1\n",
    "    lenTrain=NOP-lenValid-lenTest\n",
    "    xTrain=x.iloc[0:lenTrain,:]\n",
    "    xValid=x.iloc[lenTrain:(lenTrain+lenValid),:]\n",
    "    xTest=x.iloc[(lenTrain+lenValid):NOP,:]\n",
    "    yTrain=y.iloc[0:lenTrain,0]\n",
    "    yValid=y.iloc[lenTrain:(lenTrain+lenValid),0]\n",
    "    yTest=y.iloc[(lenTrain+lenValid):NOP,0]\n",
    "    model1 = Sequential()\n",
    "    model1.add(LSTM(256, activation='relu', input_shape=(LagLength,n_features)))\n",
    "    model1.add(Flatten())\n",
    "    model1.add(Dense(128, activation='relu'))\n",
    "    model1.add(Dense(64, activation='relu'))\n",
    "    model1.add(Dense(32, activation='relu'))\n",
    "    model1.add(Dense(1,activation='linear'))\n",
    "    checkpoint_filepath = '/cp.keras'\n",
    "    cp1=ModelCheckpoint(checkpoint_filepath,save_best_only='True')\n",
    "    model1.compile(loss=MeanSquaredError(),optimizer=Adam(learning_rate=0.01),metrics=[RootMeanSquaredError(),mean_absolute_percentage_error])\n",
    "    # fit\n",
    "    model1.fit(xTrain, yTrain,validation_data=(xValid,yValid), epochs=50, verbose=1)\n",
    "    yhatNorm=model1.predict(x).flatten().reshape(x.shape[0],1)\n",
    "    return pd.DataFrame(yhatNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1669aa52-5b55-4e56-a749-ba1398eb6c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the AQI Time Series (AQI.csv)\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ce5b65-572f-47ae-bbcc-47134a2b0e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the Linear Forecasts (linear.xlsx)\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e6a14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the Time Series Dataset\n",
    "Timeseries_Data=pd.read_csv('AQI.csv',header=None)\n",
    "linear_Data=pd.read_excel('linear.xlsx',header=None)\n",
    "Residual_Data=Timeseries_Data\n",
    "LagLength=24\n",
    "h=1\n",
    "lt=Timeseries_Data.shape[0]\n",
    "lenTrain=int(round(lt*0.7))\n",
    "lenValidation=int(round(lt*0.15))\n",
    "lenTest=int(lt-lenTrain-lenValidation)\n",
    "#Compute the Residual Series\n",
    "for i in range(lt):\n",
    "    Residual_Data.iloc[i]=Timeseries_Data.iloc[i]-linear_Data.iloc[i]\n",
    "# NORMALIZE THE DATA\n",
    "normalizedData=minmaxNorm(Residual_Data,lenTrain+lenValidation);\n",
    "# Transform the Time Series into Patterns Using Sliding Window\n",
    "X, y = get_Patterns(normalizedData, LagLength, h)\n",
    "file1=\"Accuracy.xlsx\"\n",
    "file2=\"Forecasts.xlsx\"\n",
    "Forecasts=pd.DataFrame()\n",
    "Accuracy=pd.DataFrame()\n",
    "ynorm1=Find_Fitness_LSTM(X,y,lenValidation,lenTest)\n",
    "ynorm=pd.DataFrame(normalizedData.iloc[0:(LagLength+h-1),0])\n",
    "ynorm=pd.concat([ynorm, ynorm1], ignore_index=True)\n",
    "yhat1=minmaxDeNorm(Residual_Data, ynorm, lenTrain+lenValidation)\n",
    "yhat=yhat1\n",
    "for i in range(lt):\n",
    "    yhat.iloc[i]=yhat1.iloc[i]+linear_Data.iloc[i]\n",
    "Accuracy.loc[0,0],Accuracy.loc[0,1]=findRMSE( Timeseries_Data,yhat,lenTrain+lenValidation)\n",
    "Accuracy.loc[0,2],Accuracy.loc[0,3]=findMAE( Timeseries_Data,yhat,lenTrain+lenValidation)\n",
    "Accuracy.to_excel(file1,sheet_name='Accuracy',index=False)\n",
    "yhat.to_excel(file2,sheet_name='Forecasts',index=False)\n",
    "print(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d60e1ec-9239-42a2-9ec4-d86a143d06b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
